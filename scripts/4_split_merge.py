#!/usr/bin/env python3
import csv                        # å¯¼å…¥csvæ¨¡å—ï¼Œç”¨äºè¯»å–å’Œå†™å…¥CSVæ–‡ä»¶
import os                         # å¯¼å…¥osæ¨¡å—ï¼Œç”¨äºæ–‡ä»¶å’Œè·¯å¾„æ“ä½œ
import sys                        # å¯¼å…¥sysæ¨¡å—ï¼Œç”¨äºç³»ç»Ÿç›¸å…³æ“ä½œï¼ˆå¦‚é€€å‡ºç¨‹åºï¼‰

# === è‡ªåŠ¨å®šä½ä»“åº“æ ¹ç›®å½• ===
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))   # è·å–å½“å‰è„šæœ¬æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„ï¼ˆscriptsç›®å½•ï¼‰
REPO_ROOT = os.path.dirname(SCRIPT_DIR)                   # è·å–è„šæœ¬ç›®å½•çš„ä¸Šä¸€çº§ç›®å½•ï¼Œå³ä»“åº“æ ¹ç›®å½•

def split_deep_scan(
        input_path=os.path.join(REPO_ROOT, "output/middle/merge/networksource_total.csv"),  # è¾“å…¥CSVæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤å€¼
        chunk_size=1000,                    # æ¯ä¸ªåˆ†ç‰‡æ–‡ä»¶åŒ…å«çš„æœ€å¤§è¡Œæ•°ï¼Œé»˜è®¤1000
        output_dir=os.path.join(REPO_ROOT, "output/middle/chunk")  # è¾“å‡ºåˆ†ç‰‡æ–‡ä»¶ç›®å½•ï¼Œé»˜è®¤è·¯å¾„
    ):
    """
    è¯»å– CSVï¼Œå°†å…¶æŒ‰æŒ‡å®šå¤§å°åˆ†å‰²æˆå¤šä¸ªåˆ†ç‰‡æ–‡ä»¶ chunk-N.csvã€‚
    åˆ é™¤æ—§åˆ†ç‰‡æ–‡ä»¶ï¼Œè·¯å¾„åŸºäºä»“åº“æ ¹ç›®å½•ï¼Œé¿å… GitHub Actions è·¯å¾„é”™ä¹±ã€‚
    """

    print("=== è·¯å¾„æ£€æŸ¥ ===")
    print("è„šæœ¬ç›®å½• SCRIPT_DIR:", SCRIPT_DIR)                         # è¾“å‡ºè„šæœ¬ç›®å½•è·¯å¾„ï¼Œæ–¹ä¾¿è°ƒè¯•
    print("ä»“åº“æ ¹ç›®å½• REPO_ROOT:", REPO_ROOT)                         # è¾“å‡ºä»“åº“æ ¹ç›®å½•è·¯å¾„
    print("å½“å‰å·¥ä½œç›®å½• os.getcwd():", os.getcwd())                    # è¾“å‡ºå½“å‰è¿è¡Œæ—¶çš„å·¥ä½œç›®å½•
    print("è¾“å…¥æ–‡ä»¶ç»å¯¹è·¯å¾„:", os.path.abspath(input_path))           # è¾“å‡ºè¾“å…¥æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
    print("chunk è¾“å‡ºç›®å½•ç»å¯¹è·¯å¾„:", os.path.abspath(output_dir))      # è¾“å‡ºè¾“å‡ºç›®å½•çš„ç»å¯¹è·¯å¾„

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_path):                                # å¦‚æœè¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨
        print(f"é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ - {input_path}")                # è¾“å‡ºé”™è¯¯ä¿¡æ¯
        sys.exit(1)                                                   # é€€å‡ºç¨‹åºï¼Œè¿”å›é”™è¯¯ç 1

    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    os.makedirs(output_dir, exist_ok=True)                            # åˆ›å»ºè¾“å‡ºç›®å½•ï¼Œexist_ok=Trueè¡¨ç¤ºç›®å½•å·²å­˜åœ¨ä¸æŠ¥é”™

    # === æ¸…ç†æ—§ chunk æ–‡ä»¶ ===
    print("\n=== æ¸…ç†æ—§çš„åˆ†ç‰‡æ–‡ä»¶ ===")
    for filename in os.listdir(output_dir):                           # éå†è¾“å‡ºç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
        full_path = os.path.join(output_dir, filename)                # æ‹¼æ¥æˆå®Œæ•´è·¯å¾„
        print(f"å‘ç°æ–‡ä»¶: {full_path}")                               # è¾“å‡ºæ‰¾åˆ°çš„æ–‡ä»¶å

        if filename.startswith("chunk") and filename.endswith(".csv"):  # åˆ¤æ–­æ˜¯å¦æ˜¯chunkå¼€å¤´ä¸”ä»¥.csvç»“å°¾çš„æ–‡ä»¶
            os.remove(full_path)                                      # åˆ é™¤è¯¥æ–‡ä»¶
            print(f"ğŸ‘‰ å·²åˆ é™¤: {full_path}")                          # è¾“å‡ºåˆ é™¤æç¤º
        else:
            print(f"âŒ è·³è¿‡ï¼ˆä¸æ˜¯ chunk*.csvï¼‰: {full_path}")         # ä¸æ˜¯chunkæ–‡ä»¶ï¼Œè·³è¿‡å¹¶è¾“å‡ºæç¤º

    # === è¯»å– CSV ===
    print("\n=== è¯»å– CSV æ–‡ä»¶ ===")
    try:
        with open(input_path, newline='', encoding="utf-8") as f:    # ä»¥utf-8ç¼–ç æ‰“å¼€è¾“å…¥CSVæ–‡ä»¶
            reader = csv.DictReader(f)                              # ä½¿ç”¨DictReaderæŒ‰è¡Œè¯»å–ï¼Œè¿”å›å­—å…¸æ ¼å¼
            headers = reader.fieldnames                             # è®°å½•CSVçš„åˆ—åå­—æ®µ
            rows = list(reader)                                     # å°†æ‰€æœ‰è¡Œè½¬æ¢æˆåˆ—è¡¨ï¼Œæ–¹ä¾¿åç»­å¤„ç†
    except UnicodeDecodeError:                                      # å¦‚æœutf-8è§£ç å¤±è´¥ï¼Œæ•è·å¼‚å¸¸
        print("UTF-8 è§£ç å¤±è´¥ï¼Œå°è¯•è‡ªåŠ¨æ£€æµ‹ç¼–ç ...")                 # è¾“å‡ºæç¤ºä¿¡æ¯
        import chardet                                               # å¯¼å…¥chardetåº“ï¼Œç”¨äºè‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç¼–ç 
        with open(input_path, "rb") as f:                           # ä»¥äºŒè¿›åˆ¶æ–¹å¼è¯»å–æ–‡ä»¶
            data = f.read()                                          # è¯»å–å…¨éƒ¨æ•°æ®
            detected = chardet.detect(data)                          # è‡ªåŠ¨æ£€æµ‹ç¼–ç 
            encoding = detected.get("encoding", "utf-8")             # è·å–æ£€æµ‹åˆ°çš„ç¼–ç ï¼Œé»˜è®¤utf-8

        print(f"æ£€æµ‹åˆ°ç¼–ç : {encoding}")                             # è¾“å‡ºæ£€æµ‹åˆ°çš„ç¼–ç 

        text = data.decode(encoding, errors="ignore")                # æŒ‰æ£€æµ‹ç¼–ç è§£ç æ–‡ä»¶å†…å®¹ï¼Œå¿½ç•¥é”™è¯¯
        rows = list(csv.DictReader(text.splitlines()))               # ç”¨è§£ç åçš„æ–‡æœ¬æŒ‰è¡Œè¯»å–CSVæ•°æ®
        headers = rows[0].keys() if rows else []                      # è·å–è¡¨å¤´ï¼ˆå­—æ®µåï¼‰

    total_rows = len(rows)                                           # è®¡ç®—è¯»å–çš„æ€»è¡Œæ•°
    print(f"è¯»å–è¡Œæ•°: {total_rows}")                                  # è¾“å‡ºè¡Œæ•°

    # === æ‹†åˆ† CSV ===
    total_chunks = (total_rows + chunk_size - 1) // chunk_size       # è®¡ç®—éœ€è¦ç”Ÿæˆå¤šå°‘ä¸ªchunkæ–‡ä»¶ï¼ˆå‘ä¸Šå–æ•´ï¼‰
    print(f"é¢„è®¡ç”Ÿæˆ {total_chunks} ä¸ªåˆ†ç‰‡æ–‡ä»¶")                      # è¾“å‡ºé¢„è®¡åˆ†ç‰‡æ•°é‡

    for start in range(0, total_rows, chunk_size):                    # æŒ‰chunk_sizeæ­¥é•¿å¾ªç¯åˆ†ç‰‡èµ·å§‹ä½ç½®
        chunk_rows = rows[start:start + chunk_size]                   # å–å‡ºå½“å‰åˆ†ç‰‡çš„æ‰€æœ‰è¡Œæ•°æ®
        chunk_index = start // chunk_size + 1                         # è®¡ç®—å½“å‰åˆ†ç‰‡åºå·ï¼ˆ1èµ·å§‹ï¼‰
        chunk_name = f"chunk-{chunk_index}.csv"                       # ç”Ÿæˆåˆ†ç‰‡æ–‡ä»¶å
        chunk_path = os.path.join(output_dir, chunk_name)             # æ‹¼æ¥åˆ†ç‰‡æ–‡ä»¶å®Œæ•´è·¯å¾„

        with open(chunk_path, "w", newline='', encoding="utf-8") as cf:  # ä»¥utf-8ç¼–ç å†™å…¥åˆ†ç‰‡æ–‡ä»¶
            writer = csv.DictWriter(cf, fieldnames=headers)             # åˆ›å»ºDictWriterå¯¹è±¡ï¼ŒæŒ‡å®šå­—æ®µå
            writer.writeheader()                                         # å†™å…¥CSVè¡¨å¤´
            writer.writerows(chunk_rows)                                 # å†™å…¥å½“å‰åˆ†ç‰‡çš„æ‰€æœ‰è¡Œæ•°æ®

        print(f"âœ” å·²ç”Ÿæˆ: {chunk_path}ï¼ˆè¡Œæ•° {len(chunk_rows)}ï¼‰")        # è¾“å‡ºç”Ÿæˆçš„æ–‡ä»¶åå’Œè¡Œæ•°

    print("\nğŸ‰ æ‰€æœ‰åˆ†ç‰‡æ–‡ä»¶å·²å®Œæˆ")                                   # ç»“æŸæç¤º

if __name__ == "__main__":
    split_deep_scan()   # è„šæœ¬ç›´æ¥æ‰§è¡Œæ—¶è°ƒç”¨åˆ†å‰²å‡½æ•°ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°
